{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e658f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from utilities import Hyperparameters\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e81d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR_PATH = r\"X:\\Project\\ETH\\EthereumPriceNet-master\"\n",
    "DATA_DIR_REL_PATH = 'data/'\n",
    "RAW_DATA_DIR_REL_PATH = 'data/raw/'\n",
    "DATA_DIR_ABS_PATH = os.path.join(SCRIPT_DIR_PATH, DATA_DIR_REL_PATH)\n",
    "RAW_DATA_DIR_ABS_PATH = os.path.join(SCRIPT_DIR_PATH, RAW_DATA_DIR_REL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6eb48cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RESULTS_DIR_REL_PATH = 'results/' #+ datetime.now().isoformat(' ', 'seconds') + '/'\n",
    "\n",
    "RESULTS_DIR_ABS_PATH = os.path.join(SCRIPT_DIR_PATH, RESULTS_DIR_REL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39aeedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    f_daily_avg_gas_limit = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'dailyavggaslimit.json'), 'r')\n",
    "    f_daily_avg_gas_price = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'dailyavggasprice.json'), 'r')\n",
    "    f_daily_gas_used = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'dailygasused.json'), 'r')\n",
    "    f_daily_txn_fee = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'dailytxnfee.json'), 'r')\n",
    "    f_eth_daily_market_cap = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'ethdailymarketcap.json'), 'r')\n",
    "    f_eth_daily_price = open(os.path.join(RAW_DATA_DIR_ABS_PATH, 'ethdailyprice.json'), 'r')\n",
    "\n",
    "    json_daily_avg_gas_limit = json.load(f_daily_avg_gas_limit)\n",
    "    json_daily_avg_gas_price = json.load(f_daily_avg_gas_price)\n",
    "    json_daily_gas_used = json.load(f_daily_gas_used)\n",
    "    json_daily_txn_fee = json.load(f_daily_txn_fee)\n",
    "    json_eth_daily_market_cap = json.load(f_eth_daily_market_cap)\n",
    "    json_eth_daily_price = json.load(f_eth_daily_price)\n",
    "\n",
    "    f_daily_avg_gas_limit.close()\n",
    "    f_daily_avg_gas_price.close()\n",
    "    f_daily_gas_used.close()\n",
    "    f_daily_txn_fee.close()\n",
    "    f_eth_daily_market_cap.close()\n",
    "    f_eth_daily_price.close()\n",
    "\n",
    "    daily_avg_gas_limit_data = np.asarray([[d['unixTimeStamp'], d['gasLimit']] for d in json_daily_avg_gas_limit['result']][8:], dtype=np.float64)\n",
    "    daily_avg_gas_price_data = np.asarray([[d['unixTimeStamp'], d['avgGasPrice_Wei']] for d in json_daily_avg_gas_price['result']][8:], dtype=np.float64)\n",
    "    daily_gas_used_data = np.asarray([[d['unixTimeStamp'], d['gasUsed']] for d in json_daily_gas_used['result']][8:], dtype=np.float64)\n",
    "    daily_txn_fee_data = np.asarray([[d['unixTimeStamp'], d['transactionFee_Eth']] for d in json_daily_txn_fee['result']][8:], dtype=np.float64)\n",
    "    eth_daily_market_cap_data = np.asarray([[d['unixTimeStamp'], d['marketCap']] for d in json_eth_daily_market_cap['result']][8:], dtype=np.float64)\n",
    "    eth_daily_price_data = np.asarray([[d['unixTimeStamp'], d['value']] for d in json_eth_daily_price['result']][8:], dtype=np.float64)\n",
    "\n",
    "    print(daily_avg_gas_limit_data.shape)\n",
    "\n",
    "    return (daily_avg_gas_limit_data[:, 1], daily_avg_gas_price_data[:, 1], daily_gas_used_data[:, 1], daily_txn_fee_data[:, 1], eth_daily_market_cap_data[:, 1], eth_daily_price_data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e02478d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_ffts(hps, eth_daily_price_data):\n",
    "    windows = []\n",
    "    for i in range(0, eth_daily_price_data.shape[0] - hps.fft_window_size + 1):\n",
    "        window = eth_daily_price_data[i:i + hps.fft_window_size]\n",
    "        windows += [stats.zscore(window)]\n",
    "    windows = np.vstack(windows)\n",
    "    return np.abs(np.fft.fft(windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4780455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_data(hps, full_sequence):\n",
    "    windows, y = [], []\n",
    "    for i in range(0, full_sequence.shape[0] - hps.sequence_length + 1 - hps.prediction_window_size):\n",
    "        window = full_sequence[i:i + hps.sequence_length, :]\n",
    "        windows += [window]\n",
    "        prediction_window = full_sequence[i + hps.sequence_length:i + hps.sequence_length + hps.prediction_window_size, 5]\n",
    "        y += [[\n",
    "            100*(np.amin(prediction_window)/window[-1, 5]-1),\n",
    "            100*(np.mean(prediction_window)/window[-1, 5]-1),\n",
    "            100*(np.amax(prediction_window)/window[-1, 5]-1)\n",
    "        ]]\n",
    "    return (np.stack(windows), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4a51458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 2)\n",
      "X.shape =  (2623, 14, 20)\n",
      "y.shape =  (2623, 3)\n"
     ]
    }
   ],
   "source": [
    "hps = Hyperparameters()\n",
    "\n",
    "raw_data = load_raw_data()\n",
    "eth_daily_price_data = raw_data[-1]\n",
    "price_ffts = get_price_ffts(hps, eth_daily_price_data)\n",
    "full_sequence = np.concatenate((np.stack(raw_data, axis=1)[hps.fft_window_size - 1:, :], price_ffts), axis=1)\n",
    "X, y = get_preprocessed_data(hps, full_sequence)\n",
    "\n",
    "print('X.shape = ', X.shape)\n",
    "print('y.shape = ', y.shape)\n",
    "\n",
    "np.save(os.path.join(DATA_DIR_ABS_PATH, 'X.npy'), X)\n",
    "np.save(os.path.join(DATA_DIR_ABS_PATH, 'y.npy'), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5945c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.load(os.path.join(DATA_DIR_ABS_PATH, 'X.npy'))\n",
    "    y = np.load(os.path.join(DATA_DIR_ABS_PATH, 'y.npy'))\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3697d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(hps):\n",
    "    inputs = tf.keras.Input(shape=(hps.sequence_length, 6 + hps.fft_window_size), name='lstm_inputs')\n",
    "    batch_norm = tf.keras.layers.BatchNormalization()(inputs)\n",
    "    lstm1 = tf.keras.layers.LSTM(units=hps.lstm1_units, return_sequences=True, kernel_regularizer=hps.lstm1_regularizer)(batch_norm)\n",
    "    lstm2 = tf.keras.layers.LSTM(units=hps.lstm2_units, kernel_regularizer=hps.lstm2_regularizer)(lstm1)\n",
    "    dense = tf.keras.layers.Dense(units=hps.dense_units, activation='tanh', kernel_regularizer=hps.dense_regularizer)(lstm2)\n",
    "    outputs = tf.keras.layers.Dense(units=3)(dense)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=hps.learning_rate), metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "336f9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_results(y, predictions, title):\n",
    "    plt.figure()\n",
    "    plt.plot(y[:, 0], label='actual')\n",
    "    plt.plot(predictions[:, 0], label='predicted')\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('%% change in price')\n",
    "    plt.title(title + ' (min)')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR_ABS_PATH, title + '_min.png'), dpi=600, format='png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(y[:, 1], label='actual')\n",
    "    plt.plot(predictions[:, 1], label='predicted')\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('%% change in price')\n",
    "    plt.title(title + ' (avg)')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR_ABS_PATH, title + '_avg.png'), dpi=600, format='png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(y[:, 2], label='actual')\n",
    "    plt.plot(predictions[:, 2], label='predicted')\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('%% change in price')\n",
    "    plt.title(title + ' (max)')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR_ABS_PATH, title + '_max.png'), dpi=600, format='png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0641e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_history(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss (mse)')\n",
    "    plt.title('loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR_ABS_PATH, 'loss.png'), dpi=600, format='png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['val_loss'], label='val loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss (mse)')\n",
    "    plt.title('val loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR_ABS_PATH, 'val_loss.png'), dpi=600, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11c5a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(hps, X, y):\n",
    "    index = int(hps.train_split * X.shape[0])\n",
    "    return (X[:index], y[:index], X[index:], y[index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_inputs (InputLayer)    [(None, 14, 20)]          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 20)           80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 14, 256)           283648    \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 942,163\n",
      "Trainable params: 942,123\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 7s 406ms/step - loss: 218.9332 - mae: 9.0886 - val_loss: 109.4468 - val_mae: 7.1860\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 7s 702ms/step - loss: 215.9738 - mae: 9.0350 - val_loss: 112.7845 - val_mae: 7.3638\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 209.6284 - mae: 8.9186 - val_loss: 119.9137 - val_mae: 7.7191\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 8s 762ms/step - loss: 194.6580 - mae: 8.7666 - val_loss: 126.9324 - val_mae: 8.0557\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 9s 850ms/step - loss: 182.0437 - mae: 8.8485 - val_loss: 111.1855 - val_mae: 7.3014\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 7s 700ms/step - loss: 171.3209 - mae: 8.6160 - val_loss: 84.8609 - val_mae: 6.2137\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 8s 834ms/step - loss: 167.0425 - mae: 8.4583 - val_loss: 81.5367 - val_mae: 6.3725\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 6s 650ms/step - loss: 166.7154 - mae: 8.5547 - val_loss: 80.6599 - val_mae: 6.2395\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 8s 831ms/step - loss: 165.5659 - mae: 8.4018 - val_loss: 80.9656 - val_mae: 6.1600\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 6s 638ms/step - loss: 165.0771 - mae: 8.3527 - val_loss: 81.0248 - val_mae: 6.1376\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 164.9512 - mae: 8.5204 - val_loss: 80.7638 - val_mae: 6.1333\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 7s 710ms/step - loss: 164.3944 - mae: 8.3836 - val_loss: 79.7165 - val_mae: 6.1613\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 8s 857ms/step - loss: 163.4194 - mae: 8.4554 - val_loss: 79.4540 - val_mae: 6.1534\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 162.5796 - mae: 8.4385 - val_loss: 79.1880 - val_mae: 6.1717\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 7s 710ms/step - loss: 161.8077 - mae: 8.3693 - val_loss: 79.1432 - val_mae: 6.1721\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 8s 755ms/step - loss: 161.1546 - mae: 8.3749 - val_loss: 78.8578 - val_mae: 6.2012\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 160.3122 - mae: 8.3118 - val_loss: 78.7497 - val_mae: 6.2104\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 8s 779ms/step - loss: 159.7562 - mae: 8.3992 - val_loss: 78.8578 - val_mae: 6.2022\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 158.8148 - mae: 8.2947 - val_loss: 79.2900 - val_mae: 6.1975\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 8s 829ms/step - loss: 157.4179 - mae: 8.3255 - val_loss: 78.9569 - val_mae: 6.2571\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 156.6154 - mae: 8.3126 - val_loss: 79.3818 - val_mae: 6.2592\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 9s 862ms/step - loss: 155.7829 - mae: 8.2283 - val_loss: 79.6959 - val_mae: 6.2147\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 7s 696ms/step - loss: 154.7442 - mae: 8.2687 - val_loss: 80.0841 - val_mae: 6.2343\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 9s 902ms/step - loss: 154.5970 - mae: 8.1617 - val_loss: 80.1598 - val_mae: 6.2214\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 11s 1s/step - loss: 152.8943 - mae: 8.1408 - val_loss: 80.5051 - val_mae: 6.2446\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 9s 869ms/step - loss: 151.9520 - mae: 8.1757 - val_loss: 80.7580 - val_mae: 6.3145\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 8s 843ms/step - loss: 150.1271 - mae: 8.1078 - val_loss: 81.3809 - val_mae: 6.3022\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 148.0578 - mae: 8.0040 - val_loss: 82.6875 - val_mae: 6.2844\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 149.2223 - mae: 8.1128 - val_loss: 82.2909 - val_mae: 6.3211\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 145.5862 - mae: 7.9444 - val_loss: 81.8745 - val_mae: 6.3214\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 8s 848ms/step - loss: 143.8297 - mae: 7.9391 - val_loss: 82.2021 - val_mae: 6.3294\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 8s 834ms/step - loss: 142.5889 - mae: 7.8432 - val_loss: 83.0509 - val_mae: 6.3195\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 8s 809ms/step - loss: 141.6553 - mae: 7.8573 - val_loss: 83.7151 - val_mae: 6.3753\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 139.2993 - mae: 7.7750 - val_loss: 85.6595 - val_mae: 6.5314\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 9s 906ms/step - loss: 138.2556 - mae: 7.7515 - val_loss: 83.3344 - val_mae: 6.4080\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 8s 752ms/step - loss: 137.4347 - mae: 7.7019 - val_loss: 83.8178 - val_mae: 6.4247\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 8s 767ms/step - loss: 135.4150 - mae: 7.6063 - val_loss: 87.0083 - val_mae: 6.5712\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 133.0917 - mae: 7.5752 - val_loss: 87.7072 - val_mae: 6.5911\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 133.6459 - mae: 7.5736 - val_loss: 87.0117 - val_mae: 6.5807\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 8s 769ms/step - loss: 131.6020 - mae: 7.5141 - val_loss: 90.4175 - val_mae: 6.7682\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 129.4258 - mae: 7.4813 - val_loss: 92.3557 - val_mae: 6.8764\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 130.2657 - mae: 7.4960 - val_loss: 88.5057 - val_mae: 6.6279\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 7s 728ms/step - loss: 131.5763 - mae: 7.4632 - val_loss: 95.3800 - val_mae: 6.9425\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 9s 854ms/step - loss: 125.3080 - mae: 7.3079 - val_loss: 100.2972 - val_mae: 7.2354\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 124.8769 - mae: 7.3078 - val_loss: 94.0432 - val_mae: 6.8870\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 8s 851ms/step - loss: 123.4198 - mae: 7.2498 - val_loss: 99.8938 - val_mae: 7.1655\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 7s 686ms/step - loss: 120.9343 - mae: 7.1713 - val_loss: 99.6855 - val_mae: 7.1456\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 8s 818ms/step - loss: 120.8129 - mae: 7.1635 - val_loss: 103.5811 - val_mae: 7.3886\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 117.4835 - mae: 7.0552 - val_loss: 105.6975 - val_mae: 7.4661\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 8s 828ms/step - loss: 116.7528 - mae: 7.0373 - val_loss: 108.8405 - val_mae: 7.6103\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 695ms/step - loss: 115.8261 - mae: 6.9791 - val_loss: 110.9443 - val_mae: 7.7297\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 8s 766ms/step - loss: 112.5884 - mae: 6.8946 - val_loss: 108.0504 - val_mae: 7.5617\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 112.7486 - mae: 6.8963 - val_loss: 110.4251 - val_mae: 7.6945\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 7s 692ms/step - loss: 111.0880 - mae: 6.8342 - val_loss: 115.2952 - val_mae: 7.9592\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 111.7738 - mae: 6.8237 - val_loss: 114.6477 - val_mae: 7.9162\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 6s 652ms/step - loss: 110.3382 - mae: 6.8576 - val_loss: 118.7203 - val_mae: 8.0661\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 8s 775ms/step - loss: 106.4229 - mae: 6.6812 - val_loss: 120.1894 - val_mae: 8.1352\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 6s 645ms/step - loss: 106.5681 - mae: 6.6853 - val_loss: 123.7491 - val_mae: 8.2906\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 8s 850ms/step - loss: 104.4321 - mae: 6.5773 - val_loss: 130.8055 - val_mae: 8.6878\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 7s 645ms/step - loss: 101.1012 - mae: 6.4963 - val_loss: 116.8409 - val_mae: 7.9898\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 8s 799ms/step - loss: 105.5576 - mae: 6.6584 - val_loss: 113.5757 - val_mae: 7.8288\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 104.8511 - mae: 6.6301 - val_loss: 124.6854 - val_mae: 8.3909\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 7s 687ms/step - loss: 101.7041 - mae: 6.4371 - val_loss: 119.2984 - val_mae: 8.1119\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 8s 750ms/step - loss: 102.3431 - mae: 6.5450 - val_loss: 124.0407 - val_mae: 8.3759\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 100.3927 - mae: 6.4897 - val_loss: 125.5549 - val_mae: 8.4402\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 8s 792ms/step - loss: 100.3400 - mae: 6.4509 - val_loss: 126.4418 - val_mae: 8.4548\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 97.5437 - mae: 6.3938 - val_loss: 136.8503 - val_mae: 9.0115\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 8s 834ms/step - loss: 97.5162 - mae: 6.3760 - val_loss: 116.7298 - val_mae: 7.9638\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 93.9434 - mae: 6.2801 - val_loss: 121.7726 - val_mae: 8.2167\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 8s 830ms/step - loss: 92.7609 - mae: 6.2114 - val_loss: 129.7283 - val_mae: 8.6381\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 90.9363 - mae: 6.1309 - val_loss: 122.7694 - val_mae: 8.2783\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 8s 773ms/step - loss: 88.6565 - mae: 6.0486 - val_loss: 129.1279 - val_mae: 8.6138\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 92.0297 - mae: 6.1131 - val_loss: 126.5977 - val_mae: 8.5062\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 95.4790 - mae: 6.2716 - val_loss: 132.2425 - val_mae: 8.7109\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 91.0642 - mae: 6.1583 - val_loss: 130.7434 - val_mae: 8.6687\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 7s 687ms/step - loss: 90.2558 - mae: 6.1413 - val_loss: 135.5207 - val_mae: 8.8919\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 8s 776ms/step - loss: 97.1384 - mae: 6.3936 - val_loss: 142.3289 - val_mae: 9.2173\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 6s 644ms/step - loss: 91.7942 - mae: 6.2117 - val_loss: 120.7283 - val_mae: 8.1108\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 8s 810ms/step - loss: 87.9623 - mae: 6.0569 - val_loss: 130.2631 - val_mae: 8.6431\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 6s 648ms/step - loss: 85.4035 - mae: 5.9274 - val_loss: 126.4022 - val_mae: 8.4684\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 8s 790ms/step - loss: 81.8490 - mae: 5.8000 - val_loss: 132.2645 - val_mae: 8.6820\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 80.2829 - mae: 5.7471 - val_loss: 132.7060 - val_mae: 8.7516\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 7s 697ms/step - loss: 81.4810 - mae: 5.7920 - val_loss: 137.0557 - val_mae: 8.9372\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 8s 777ms/step - loss: 79.3481 - mae: 5.6798 - val_loss: 126.6643 - val_mae: 8.4956\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 7s 711ms/step - loss: 78.2123 - mae: 5.6465 - val_loss: 134.8676 - val_mae: 8.8323\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 79.0652 - mae: 5.6730 - val_loss: 126.6741 - val_mae: 8.4569\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 6s 642ms/step - loss: 78.6333 - mae: 5.6558 - val_loss: 145.6224 - val_mae: 9.2928\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 8s 789ms/step - loss: 75.6922 - mae: 5.5528 - val_loss: 130.8234 - val_mae: 8.6431\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 76.5627 - mae: 5.5652 - val_loss: 136.2422 - val_mae: 8.8743\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 8s 835ms/step - loss: 77.6111 - mae: 5.6111 - val_loss: 133.2588 - val_mae: 8.7682\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 7s 659ms/step - loss: 73.5290 - mae: 5.4273 - val_loss: 128.8484 - val_mae: 8.5566\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 8s 791ms/step - loss: 75.1628 - mae: 5.4860 - val_loss: 130.6812 - val_mae: 8.6306\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 71.5533 - mae: 5.3909 - val_loss: 147.3586 - val_mae: 9.3899\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 7s 746ms/step - loss: 71.6553 - mae: 5.3827 - val_loss: 118.7830 - val_mae: 8.0383\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 7s 733ms/step - loss: 72.1586 - mae: 5.3942 - val_loss: 127.8907 - val_mae: 8.4434\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 7s 727ms/step - loss: 73.2198 - mae: 5.4372 - val_loss: 141.6870 - val_mae: 9.1458\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 70.9491 - mae: 5.3395 - val_loss: 131.5442 - val_mae: 8.6188\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 6s 643ms/step - loss: 67.7880 - mae: 5.2144 - val_loss: 139.9937 - val_mae: 9.0040\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 75.6690 - mae: 5.5189 - val_loss: 153.5548 - val_mae: 9.6176\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 7s 704ms/step - loss: 72.8712 - mae: 5.4028 - val_loss: 130.3184 - val_mae: 8.5626\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 9s 865ms/step - loss: 67.5763 - mae: 5.1696 - val_loss: 141.0681 - val_mae: 9.1565\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 7s 667ms/step - loss: 66.6751 - mae: 5.1356 - val_loss: 125.4640 - val_mae: 8.3572\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 8s 806ms/step - loss: 65.0370 - mae: 5.0929 - val_loss: 131.2859 - val_mae: 8.6326\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 7s 647ms/step - loss: 66.2497 - mae: 5.1245 - val_loss: 134.5438 - val_mae: 8.7318\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 70.1442 - mae: 5.3613 - val_loss: 132.8102 - val_mae: 8.6841\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 64.6682 - mae: 5.0988 - val_loss: 158.7960 - val_mae: 9.8415\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 7s 729ms/step - loss: 62.9936 - mae: 5.0279 - val_loss: 123.1951 - val_mae: 8.1762\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 63.5657 - mae: 5.0557 - val_loss: 146.1316 - val_mae: 9.3143\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 8s 861ms/step - loss: 62.8828 - mae: 4.9801 - val_loss: 127.4873 - val_mae: 8.3844\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 774ms/step - loss: 61.3735 - mae: 4.9297 - val_loss: 127.9478 - val_mae: 8.4637\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 63.2414 - mae: 4.9996 - val_loss: 138.3820 - val_mae: 8.9874\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 9s 904ms/step - loss: 60.6426 - mae: 4.9197 - val_loss: 125.1189 - val_mae: 8.3503\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 59.6117 - mae: 4.8260 - val_loss: 144.2682 - val_mae: 9.2357\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 9s 865ms/step - loss: 58.9121 - mae: 4.7965 - val_loss: 123.6247 - val_mae: 8.2752\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 7s 667ms/step - loss: 58.4370 - mae: 4.8105 - val_loss: 132.4860 - val_mae: 8.6646\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 9s 876ms/step - loss: 58.1884 - mae: 4.7876 - val_loss: 132.3649 - val_mae: 8.6552\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 7s 666ms/step - loss: 57.4063 - mae: 4.7258 - val_loss: 145.3825 - val_mae: 9.3028\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 8s 813ms/step - loss: 56.3276 - mae: 4.6735 - val_loss: 122.9857 - val_mae: 8.2750\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 8s 768ms/step - loss: 56.2181 - mae: 4.6815 - val_loss: 138.9793 - val_mae: 8.9791\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 8s 838ms/step - loss: 60.2707 - mae: 4.8737 - val_loss: 129.6279 - val_mae: 8.5825\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 7s 693ms/step - loss: 56.3455 - mae: 4.6905 - val_loss: 130.8602 - val_mae: 8.6043\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 55.8292 - mae: 4.6895 - val_loss: 128.0669 - val_mae: 8.4795\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 54.4669 - mae: 4.6034 - val_loss: 136.1578 - val_mae: 8.8419\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 8s 847ms/step - loss: 54.1267 - mae: 4.5786 - val_loss: 121.5685 - val_mae: 8.1664\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 10s 950ms/step - loss: 53.7603 - mae: 4.5567 - val_loss: 133.8063 - val_mae: 8.7111\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 8s 866ms/step - loss: 54.6911 - mae: 4.6200 - val_loss: 124.3340 - val_mae: 8.3533\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 54.1185 - mae: 4.5605 - val_loss: 134.8443 - val_mae: 8.8186\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 8s 810ms/step - loss: 53.9615 - mae: 4.5978 - val_loss: 133.7142 - val_mae: 8.7409\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 7s 708ms/step - loss: 56.4841 - mae: 4.7022 - val_loss: 118.0540 - val_mae: 8.0493\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 9s 895ms/step - loss: 53.8689 - mae: 4.6152 - val_loss: 142.3160 - val_mae: 9.1491\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 10s 877ms/step - loss: 53.6709 - mae: 4.5775 - val_loss: 138.7077 - val_mae: 9.0396\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 9s 922ms/step - loss: 51.4321 - mae: 4.4866 - val_loss: 121.2934 - val_mae: 8.1423\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 13s 1s/step - loss: 50.7124 - mae: 4.4404 - val_loss: 134.5454 - val_mae: 8.7836\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 9s 831ms/step - loss: 50.9721 - mae: 4.4843 - val_loss: 114.1342 - val_mae: 7.8599\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 9s 915ms/step - loss: 51.1583 - mae: 4.4488 - val_loss: 134.5617 - val_mae: 8.8018\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 9s 936ms/step - loss: 51.6720 - mae: 4.4511 - val_loss: 144.4751 - val_mae: 9.2945\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 9s 913ms/step - loss: 49.8096 - mae: 4.4069 - val_loss: 128.5862 - val_mae: 8.4850\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 49.5304 - mae: 4.3521 - val_loss: 125.4966 - val_mae: 8.3830\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 10s 1s/step - loss: 47.1300 - mae: 4.2524 - val_loss: 128.5976 - val_mae: 8.5508\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 7s 730ms/step - loss: 48.3811 - mae: 4.3150 - val_loss: 120.2290 - val_mae: 8.0812\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 8s 817ms/step - loss: 47.0000 - mae: 4.2224 - val_loss: 120.8032 - val_mae: 8.1672\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 7s 719ms/step - loss: 46.7954 - mae: 4.2274 - val_loss: 119.9625 - val_mae: 8.0888\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 8s 797ms/step - loss: 48.2478 - mae: 4.3154 - val_loss: 145.3799 - val_mae: 9.2583\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 7s 691ms/step - loss: 54.6412 - mae: 4.6020 - val_loss: 114.4572 - val_mae: 7.8515\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 8s 858ms/step - loss: 49.9488 - mae: 4.4109 - val_loss: 118.8224 - val_mae: 8.0797\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 7s 749ms/step - loss: 46.8106 - mae: 4.2639 - val_loss: 140.4078 - val_mae: 9.0718\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 9s 974ms/step - loss: 45.5579 - mae: 4.1766 - val_loss: 125.9696 - val_mae: 8.3965\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 44.7673 - mae: 4.1272 - val_loss: 127.8647 - val_mae: 8.4726\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 8s 797ms/step - loss: 44.6447 - mae: 4.1339 - val_loss: 123.5434 - val_mae: 8.2693\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 7s 665ms/step - loss: 44.5555 - mae: 4.1165 - val_loss: 134.4670 - val_mae: 8.7779\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 45.1784 - mae: 4.1493 - val_loss: 119.5051 - val_mae: 8.0390\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 11s 1s/step - loss: 44.7980 - mae: 4.1353 - val_loss: 115.7038 - val_mae: 7.8889\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 11s 1s/step - loss: 45.6341 - mae: 4.1938 - val_loss: 138.9904 - val_mae: 9.0206\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 8s 811ms/step - loss: 44.9044 - mae: 4.1302 - val_loss: 124.6976 - val_mae: 8.3586\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 8s 745ms/step - loss: 44.2872 - mae: 4.1181 - val_loss: 115.9942 - val_mae: 7.9942\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 8s 772ms/step - loss: 45.4681 - mae: 4.1736 - val_loss: 120.8160 - val_mae: 8.1534\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 8s 742ms/step - loss: 45.2926 - mae: 4.1795 - val_loss: 121.2430 - val_mae: 8.1821\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 43.1491 - mae: 4.0571 - val_loss: 128.8938 - val_mae: 8.5420\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 8s 787ms/step - loss: 42.7699 - mae: 4.0066 - val_loss: 129.2119 - val_mae: 8.5582\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 7s 686ms/step - loss: 42.8827 - mae: 4.0534 - val_loss: 117.4392 - val_mae: 7.9357\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 8s 826ms/step - loss: 42.0683 - mae: 4.0102 - val_loss: 129.1264 - val_mae: 8.5553\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 41.1576 - mae: 3.9143 - val_loss: 121.9646 - val_mae: 8.2381\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 9s 883ms/step - loss: 41.2091 - mae: 3.9431 - val_loss: 128.8680 - val_mae: 8.4848\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 10s 1s/step - loss: 43.1626 - mae: 4.0334 - val_loss: 110.9823 - val_mae: 7.6905\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 8s 789ms/step - loss: 43.8907 - mae: 4.1352 - val_loss: 106.5441 - val_mae: 7.4771\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 7s 694ms/step - loss: 41.9790 - mae: 4.0370 - val_loss: 124.0025 - val_mae: 8.2784\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 40.4398 - mae: 3.9192 - val_loss: 126.6602 - val_mae: 8.5069\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 7s 697ms/step - loss: 40.0453 - mae: 3.8847 - val_loss: 118.3733 - val_mae: 8.0173\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 770ms/step - loss: 39.2788 - mae: 3.8165 - val_loss: 111.3618 - val_mae: 7.6701\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 6s 644ms/step - loss: 40.5693 - mae: 3.9168 - val_loss: 140.8997 - val_mae: 9.1217\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 8s 813ms/step - loss: 39.9044 - mae: 3.8810 - val_loss: 114.2822 - val_mae: 7.8361\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 39.2542 - mae: 3.8400 - val_loss: 115.6150 - val_mae: 7.9435\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 8s 843ms/step - loss: 40.1605 - mae: 3.8857 - val_loss: 123.1168 - val_mae: 8.2503\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 40.6602 - mae: 3.9046 - val_loss: 124.8435 - val_mae: 8.3460\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 7s 713ms/step - loss: 37.5393 - mae: 3.7067 - val_loss: 124.5513 - val_mae: 8.3167\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 37.8303 - mae: 3.7647 - val_loss: 123.5305 - val_mae: 8.2996\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 7s 692ms/step - loss: 38.4201 - mae: 3.7972 - val_loss: 121.9535 - val_mae: 8.1794\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 8s 789ms/step - loss: 38.0819 - mae: 3.7325 - val_loss: 126.3170 - val_mae: 8.3695\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 40.6449 - mae: 3.9289 - val_loss: 107.6774 - val_mae: 7.4938\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 9s 877ms/step - loss: 39.1339 - mae: 3.8845 - val_loss: 124.6521 - val_mae: 8.3136\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 37.9515 - mae: 3.8003 - val_loss: 124.9053 - val_mae: 8.2776\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 8s 825ms/step - loss: 38.2414 - mae: 3.8015 - val_loss: 116.9977 - val_mae: 7.9640\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 7s 655ms/step - loss: 36.9107 - mae: 3.6836 - val_loss: 109.5406 - val_mae: 7.5815\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 37.6939 - mae: 3.7103 - val_loss: 129.4663 - val_mae: 8.5122\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 7s 666ms/step - loss: 37.9370 - mae: 3.7886 - val_loss: 110.7071 - val_mae: 7.6575\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 8s 811ms/step - loss: 38.0425 - mae: 3.8032 - val_loss: 119.2507 - val_mae: 8.0984\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 7s 728ms/step - loss: 38.4147 - mae: 3.7747 - val_loss: 114.7128 - val_mae: 7.8724\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 38.2664 - mae: 3.7906 - val_loss: 117.6129 - val_mae: 7.9794\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 7s 720ms/step - loss: 36.3433 - mae: 3.6946 - val_loss: 125.4527 - val_mae: 8.3779\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 7s 715ms/step - loss: 36.1800 - mae: 3.6290 - val_loss: 118.2114 - val_mae: 8.0515\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 35.6659 - mae: 3.6501 - val_loss: 123.8202 - val_mae: 8.2654\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 7s 666ms/step - loss: 35.0177 - mae: 3.6030 - val_loss: 117.9291 - val_mae: 7.9913\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 8s 778ms/step - loss: 34.7352 - mae: 3.5497 - val_loss: 111.0431 - val_mae: 7.6178\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 7s 694ms/step - loss: 34.7455 - mae: 3.5589 - val_loss: 118.4584 - val_mae: 7.9730\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 8s 845ms/step - loss: 33.3844 - mae: 3.4585 - val_loss: 127.3478 - val_mae: 8.4516\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 7s 659ms/step - loss: 33.5032 - mae: 3.4923 - val_loss: 116.5809 - val_mae: 7.9298\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 8s 829ms/step - loss: 33.6811 - mae: 3.4847 - val_loss: 118.4747 - val_mae: 8.0182\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 7s 701ms/step - loss: 33.5477 - mae: 3.4721 - val_loss: 123.1653 - val_mae: 8.2647\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 8s 787ms/step - loss: 32.4768 - mae: 3.3988 - val_loss: 119.6979 - val_mae: 8.0961\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 7s 714ms/step - loss: 34.0206 - mae: 3.5373 - val_loss: 129.8773 - val_mae: 8.5498\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 34.9738 - mae: 3.5916 - val_loss: 118.3317 - val_mae: 8.0318\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 8s 756ms/step - loss: 33.9786 - mae: 3.5127 - val_loss: 118.1156 - val_mae: 7.9755\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 7s 676ms/step - loss: 32.8161 - mae: 3.4259 - val_loss: 128.4635 - val_mae: 8.4582\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 8s 761ms/step - loss: 33.2687 - mae: 3.4822 - val_loss: 112.2963 - val_mae: 7.7397\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 7s 665ms/step - loss: 33.5536 - mae: 3.5214 - val_loss: 116.7855 - val_mae: 7.9777\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 8s 822ms/step - loss: 32.0734 - mae: 3.4135 - val_loss: 118.1379 - val_mae: 7.9409\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 7s 660ms/step - loss: 31.3758 - mae: 3.3378 - val_loss: 113.4489 - val_mae: 7.7466\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 8s 828ms/step - loss: 31.9375 - mae: 3.3971 - val_loss: 116.8548 - val_mae: 7.9288\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 31.0496 - mae: 3.3120 - val_loss: 119.7670 - val_mae: 7.9981\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 31.4104 - mae: 3.3566 - val_loss: 119.5061 - val_mae: 7.9782\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 32.3442 - mae: 3.4201 - val_loss: 120.2075 - val_mae: 8.0828\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 8s 765ms/step - loss: 32.1245 - mae: 3.4072 - val_loss: 121.3710 - val_mae: 8.0753\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 7s 702ms/step - loss: 31.9676 - mae: 3.4120 - val_loss: 116.5836 - val_mae: 7.9610\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 7s 701ms/step - loss: 31.7933 - mae: 3.3743 - val_loss: 115.4014 - val_mae: 7.8016\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 7s 736ms/step - loss: 32.6606 - mae: 3.4730 - val_loss: 120.5689 - val_mae: 8.0534\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 7s 660ms/step - loss: 32.2051 - mae: 3.4812 - val_loss: 110.9285 - val_mae: 7.7011\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 8s 822ms/step - loss: 33.3682 - mae: 3.5187 - val_loss: 115.7648 - val_mae: 7.8374\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 6s 647ms/step - loss: 34.2801 - mae: 3.5638 - val_loss: 119.9700 - val_mae: 8.0561\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 8s 831ms/step - loss: 33.2718 - mae: 3.5280 - val_loss: 107.5086 - val_mae: 7.4532\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 31.1450 - mae: 3.3832 - val_loss: 121.0552 - val_mae: 7.9949\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 8s 827ms/step - loss: 31.0870 - mae: 3.3383 - val_loss: 115.9130 - val_mae: 7.8672\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 7s 714ms/step - loss: 32.1797 - mae: 3.4294 - val_loss: 114.3921 - val_mae: 7.8506\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 31.5039 - mae: 3.4130 - val_loss: 114.9720 - val_mae: 7.8117\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 7s 705ms/step - loss: 30.3535 - mae: 3.2995 - val_loss: 108.3470 - val_mae: 7.5231\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 29.1022 - mae: 3.1989 - val_loss: 119.1697 - val_mae: 8.0105\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 8s 738ms/step - loss: 29.2514 - mae: 3.2148 - val_loss: 114.5250 - val_mae: 7.9092\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 28.6927 - mae: 3.1941 - val_loss: 110.6733 - val_mae: 7.6619\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 698ms/step - loss: 28.8333 - mae: 3.1948 - val_loss: 113.2741 - val_mae: 7.7111\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 28.5159 - mae: 3.1815 - val_loss: 120.8125 - val_mae: 8.1485\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 8s 749ms/step - loss: 28.6496 - mae: 3.1957 - val_loss: 115.6615 - val_mae: 7.9161\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 6s 641ms/step - loss: 27.9604 - mae: 3.1314 - val_loss: 112.7276 - val_mae: 7.7526\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 8s 816ms/step - loss: 28.7305 - mae: 3.2310 - val_loss: 114.1576 - val_mae: 7.7631\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 7s 674ms/step - loss: 29.0156 - mae: 3.2239 - val_loss: 114.7749 - val_mae: 7.7315\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 8s 808ms/step - loss: 28.6569 - mae: 3.1800 - val_loss: 115.0922 - val_mae: 7.8652\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 7s 687ms/step - loss: 29.7855 - mae: 3.2678 - val_loss: 110.1883 - val_mae: 7.6209\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 8s 767ms/step - loss: 28.6071 - mae: 3.1973 - val_loss: 109.4575 - val_mae: 7.5194\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 7s 677ms/step - loss: 28.4203 - mae: 3.1562 - val_loss: 109.1270 - val_mae: 7.5154\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 7s 699ms/step - loss: 27.4676 - mae: 3.0991 - val_loss: 122.2987 - val_mae: 8.1778\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 28.4048 - mae: 3.1795 - val_loss: 113.9652 - val_mae: 7.7705\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 7s 677ms/step - loss: 27.4916 - mae: 3.1173 - val_loss: 111.5906 - val_mae: 7.6973\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 27.6972 - mae: 3.0965 - val_loss: 114.8770 - val_mae: 7.8863\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 7s 667ms/step - loss: 27.2018 - mae: 3.0946 - val_loss: 115.2812 - val_mae: 7.8094\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 8s 832ms/step - loss: 27.0827 - mae: 3.0783 - val_loss: 109.6881 - val_mae: 7.6591\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 7s 670ms/step - loss: 27.9424 - mae: 3.1619 - val_loss: 112.2405 - val_mae: 7.7367\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 26.5163 - mae: 3.0187 - val_loss: 115.4780 - val_mae: 7.8752\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 26.3437 - mae: 3.0387 - val_loss: 111.9658 - val_mae: 7.8018\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 8s 799ms/step - loss: 26.7843 - mae: 3.0631 - val_loss: 114.9222 - val_mae: 7.7759\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 27.7773 - mae: 3.1517 - val_loss: 112.0988 - val_mae: 7.6674\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 7s 706ms/step - loss: 27.6649 - mae: 3.1238 - val_loss: 113.1458 - val_mae: 7.6375\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 8s 796ms/step - loss: 27.2727 - mae: 3.1469 - val_loss: 106.0756 - val_mae: 7.5168\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 27.3937 - mae: 3.1088 - val_loss: 108.4184 - val_mae: 7.6014\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 26.8617 - mae: 3.0779 - val_loss: 117.0915 - val_mae: 7.9372\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 25.0944 - mae: 2.9328 - val_loss: 107.6101 - val_mae: 7.5041\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 8s 793ms/step - loss: 27.0379 - mae: 3.0855 - val_loss: 115.3552 - val_mae: 7.8823\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 6s 638ms/step - loss: 27.2699 - mae: 3.1165 - val_loss: 112.0667 - val_mae: 7.6947\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 8s 798ms/step - loss: 26.4925 - mae: 3.0986 - val_loss: 113.9900 - val_mae: 7.7350\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 27.6055 - mae: 3.1852 - val_loss: 109.0841 - val_mae: 7.4926\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 8s 783ms/step - loss: 26.7752 - mae: 3.0840 - val_loss: 116.3262 - val_mae: 7.8380\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 7s 674ms/step - loss: 27.1251 - mae: 3.0718 - val_loss: 116.8524 - val_mae: 7.9044\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 26.5317 - mae: 3.0562 - val_loss: 110.4888 - val_mae: 7.5640\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 8s 755ms/step - loss: 26.0881 - mae: 3.0381 - val_loss: 110.4703 - val_mae: 7.6491\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 25.6586 - mae: 3.0170 - val_loss: 114.8801 - val_mae: 7.8263\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 8s 776ms/step - loss: 25.8135 - mae: 3.0221 - val_loss: 119.0484 - val_mae: 8.0697\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 6s 639ms/step - loss: 26.2362 - mae: 3.0472 - val_loss: 108.7140 - val_mae: 7.5237\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 8s 841ms/step - loss: 25.3179 - mae: 2.9777 - val_loss: 114.6998 - val_mae: 7.8717\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 24.7805 - mae: 2.9464 - val_loss: 113.6865 - val_mae: 7.7471\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 8s 834ms/step - loss: 25.1403 - mae: 2.9587 - val_loss: 116.1032 - val_mae: 7.9543\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 7s 704ms/step - loss: 24.7207 - mae: 2.9076 - val_loss: 112.9394 - val_mae: 7.7123\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 8s 804ms/step - loss: 25.5197 - mae: 3.0059 - val_loss: 118.3955 - val_mae: 7.9886\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 7s 706ms/step - loss: 26.3740 - mae: 3.0677 - val_loss: 112.9936 - val_mae: 7.6157\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 7s 725ms/step - loss: 24.7168 - mae: 2.9437 - val_loss: 113.8569 - val_mae: 7.6998\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 7s 707ms/step - loss: 24.8093 - mae: 2.9248 - val_loss: 108.9243 - val_mae: 7.5442\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 24.8498 - mae: 2.9322 - val_loss: 114.3255 - val_mae: 7.7446\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 8s 792ms/step - loss: 24.3211 - mae: 2.8555 - val_loss: 110.9977 - val_mae: 7.6660\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 7s 703ms/step - loss: 27.1189 - mae: 3.1400 - val_loss: 120.4160 - val_mae: 8.0275\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 8s 809ms/step - loss: 25.3950 - mae: 2.9979 - val_loss: 109.9546 - val_mae: 7.5247\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 7s 670ms/step - loss: 24.7437 - mae: 2.9668 - val_loss: 111.1767 - val_mae: 7.5645\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 8s 844ms/step - loss: 23.7373 - mae: 2.8737 - val_loss: 115.5330 - val_mae: 7.8618\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 7s 706ms/step - loss: 23.4790 - mae: 2.8252 - val_loss: 108.5466 - val_mae: 7.5481\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 8s 864ms/step - loss: 24.1674 - mae: 2.9063 - val_loss: 111.0291 - val_mae: 7.7659\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 7s 655ms/step - loss: 27.0158 - mae: 3.1749 - val_loss: 115.9241 - val_mae: 7.8891\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 26.0405 - mae: 3.0985 - val_loss: 113.8069 - val_mae: 7.7277\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 7s 694ms/step - loss: 24.2431 - mae: 2.9311 - val_loss: 107.2933 - val_mae: 7.4507\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 8s 783ms/step - loss: 24.8591 - mae: 2.9906 - val_loss: 109.5937 - val_mae: 7.5232\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 7s 688ms/step - loss: 23.8957 - mae: 2.8704 - val_loss: 110.6025 - val_mae: 7.6588\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 7s 726ms/step - loss: 23.3937 - mae: 2.8192 - val_loss: 109.1416 - val_mae: 7.5266\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 715ms/step - loss: 23.4463 - mae: 2.8446 - val_loss: 110.3987 - val_mae: 7.5640\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 6s 634ms/step - loss: 23.8858 - mae: 2.9154 - val_loss: 113.6626 - val_mae: 7.7421\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 7s 745ms/step - loss: 22.5711 - mae: 2.7808 - val_loss: 110.5599 - val_mae: 7.5491\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 6s 620ms/step - loss: 24.3906 - mae: 2.8997 - val_loss: 109.9272 - val_mae: 7.4848\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 8s 769ms/step - loss: 24.0034 - mae: 2.9405 - val_loss: 111.5998 - val_mae: 7.7594\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 7s 675ms/step - loss: 23.2745 - mae: 2.8245 - val_loss: 119.4392 - val_mae: 8.0400\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 7s 739ms/step - loss: 22.9463 - mae: 2.8378 - val_loss: 109.1963 - val_mae: 7.5018\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 7s 700ms/step - loss: 23.7791 - mae: 2.8804 - val_loss: 109.2675 - val_mae: 7.5460\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 7s 666ms/step - loss: 22.4576 - mae: 2.7744 - val_loss: 111.9263 - val_mae: 7.5899\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 8s 761ms/step - loss: 22.2189 - mae: 2.7482 - val_loss: 111.7376 - val_mae: 7.6315\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 6s 651ms/step - loss: 22.1233 - mae: 2.7529 - val_loss: 107.1938 - val_mae: 7.4573\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 8s 815ms/step - loss: 22.8744 - mae: 2.8007 - val_loss: 118.2310 - val_mae: 7.9524\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 7s 687ms/step - loss: 22.0244 - mae: 2.7623 - val_loss: 117.1286 - val_mae: 7.9408\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 21.8084 - mae: 2.7365 - val_loss: 109.8106 - val_mae: 7.5441\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 22.1397 - mae: 2.7513 - val_loss: 110.2078 - val_mae: 7.5795\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 7s 756ms/step - loss: 23.6532 - mae: 2.8536 - val_loss: 115.4253 - val_mae: 7.8061\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 22.7680 - mae: 2.7998 - val_loss: 110.6385 - val_mae: 7.7299\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 7s 706ms/step - loss: 22.9446 - mae: 2.7957 - val_loss: 116.7571 - val_mae: 7.9645\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 7s 723ms/step - loss: 24.5714 - mae: 2.9209 - val_loss: 115.4765 - val_mae: 7.8191\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 6s 624ms/step - loss: 24.5368 - mae: 2.9267 - val_loss: 107.0153 - val_mae: 7.5025\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 8s 781ms/step - loss: 21.8880 - mae: 2.7179 - val_loss: 114.1828 - val_mae: 7.7531\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 7s 653ms/step - loss: 21.4185 - mae: 2.6864 - val_loss: 113.1996 - val_mae: 7.8570\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 8s 769ms/step - loss: 22.1852 - mae: 2.7695 - val_loss: 114.9102 - val_mae: 7.8539\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 7s 659ms/step - loss: 21.1520 - mae: 2.6526 - val_loss: 115.4507 - val_mae: 7.8331\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 7s 758ms/step - loss: 20.7678 - mae: 2.6376 - val_loss: 106.8787 - val_mae: 7.4879\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 7s 722ms/step - loss: 21.4468 - mae: 2.6901 - val_loss: 118.7852 - val_mae: 7.9863\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 7s 734ms/step - loss: 21.3401 - mae: 2.6656 - val_loss: 112.4145 - val_mae: 7.7263\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 8s 745ms/step - loss: 20.7801 - mae: 2.6348 - val_loss: 109.9679 - val_mae: 7.6007\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 6s 630ms/step - loss: 19.7377 - mae: 2.5238 - val_loss: 110.6063 - val_mae: 7.5667\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 8s 861ms/step - loss: 20.0778 - mae: 2.5363 - val_loss: 111.0079 - val_mae: 7.6048\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 7s 672ms/step - loss: 21.4934 - mae: 2.7034 - val_loss: 110.9839 - val_mae: 7.6312\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 8s 823ms/step - loss: 20.4674 - mae: 2.6034 - val_loss: 111.9986 - val_mae: 7.6236\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 7s 652ms/step - loss: 20.8641 - mae: 2.6781 - val_loss: 111.0231 - val_mae: 7.6969\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 8s 790ms/step - loss: 20.3214 - mae: 2.5961 - val_loss: 117.4817 - val_mae: 8.0071\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 7s 663ms/step - loss: 21.6447 - mae: 2.6903 - val_loss: 119.1865 - val_mae: 8.0525\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 7s 721ms/step - loss: 21.7674 - mae: 2.7189 - val_loss: 110.5820 - val_mae: 7.6069\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 7s 741ms/step - loss: 22.5653 - mae: 2.7382 - val_loss: 111.7173 - val_mae: 7.6799\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 7s 667ms/step - loss: 23.6649 - mae: 2.8374 - val_loss: 113.6548 - val_mae: 7.6762\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 8s 765ms/step - loss: 20.8069 - mae: 2.6578 - val_loss: 106.0814 - val_mae: 7.4486\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 7s 659ms/step - loss: 21.3300 - mae: 2.7432 - val_loss: 118.1677 - val_mae: 7.9086\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 8s 823ms/step - loss: 20.9981 - mae: 2.6811 - val_loss: 116.2850 - val_mae: 7.8187\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 6s 649ms/step - loss: 20.0765 - mae: 2.5957 - val_loss: 108.4048 - val_mae: 7.5269\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 8s 829ms/step - loss: 20.8358 - mae: 2.6789 - val_loss: 114.0220 - val_mae: 7.7613\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 7s 653ms/step - loss: 19.7667 - mae: 2.5665 - val_loss: 114.9713 - val_mae: 7.8326\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 8s 775ms/step - loss: 19.0069 - mae: 2.4664 - val_loss: 112.7256 - val_mae: 7.6414\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 7s 731ms/step - loss: 19.9745 - mae: 2.5873 - val_loss: 111.9382 - val_mae: 7.6425\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 7s 700ms/step - loss: 19.8171 - mae: 2.5672 - val_loss: 111.3847 - val_mae: 7.5571\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 20.0393 - mae: 2.5901 - val_loss: 111.9749 - val_mae: 7.6844\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 7s 684ms/step - loss: 19.7083 - mae: 2.5429 - val_loss: 110.7409 - val_mae: 7.5943\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 19.8917 - mae: 2.5829 - val_loss: 115.0469 - val_mae: 7.7926\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 7s 659ms/step - loss: 19.1238 - mae: 2.5033 - val_loss: 109.5207 - val_mae: 7.5312\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 8s 819ms/step - loss: 19.5832 - mae: 2.5445 - val_loss: 113.0022 - val_mae: 7.7048\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 7s 674ms/step - loss: 18.6990 - mae: 2.4628 - val_loss: 113.1087 - val_mae: 7.6722\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 18.6661 - mae: 2.4658 - val_loss: 111.7247 - val_mae: 7.6035\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 19.2576 - mae: 2.5010 - val_loss: 112.9778 - val_mae: 7.7368\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 8s 788ms/step - loss: 20.6322 - mae: 2.6266 - val_loss: 114.1249 - val_mae: 7.7849\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 23.6918 - mae: 2.8924 - val_loss: 118.8214 - val_mae: 7.9862\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 8s 773ms/step - loss: 21.0744 - mae: 2.7596 - val_loss: 107.2485 - val_mae: 7.4917\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 7s 725ms/step - loss: 20.2223 - mae: 2.6619 - val_loss: 110.6280 - val_mae: 7.5754\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 7s 712ms/step - loss: 18.9165 - mae: 2.4979 - val_loss: 107.9825 - val_mae: 7.4633\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 8s 765ms/step - loss: 18.8781 - mae: 2.4757 - val_loss: 109.8387 - val_mae: 7.5881\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 7s 658ms/step - loss: 18.9322 - mae: 2.4908 - val_loss: 109.9342 - val_mae: 7.6075\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 18.4762 - mae: 2.4616 - val_loss: 107.6379 - val_mae: 7.5024\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 7s 650ms/step - loss: 19.3538 - mae: 2.5402 - val_loss: 113.8948 - val_mae: 7.7402\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 8s 822ms/step - loss: 18.7455 - mae: 2.5026 - val_loss: 112.9084 - val_mae: 7.6820\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 7s 648ms/step - loss: 18.0761 - mae: 2.4121 - val_loss: 111.8903 - val_mae: 7.7055\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 8s 778ms/step - loss: 18.3746 - mae: 2.4693 - val_loss: 115.0546 - val_mae: 7.6969\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 8s 753ms/step - loss: 18.1447 - mae: 2.4105 - val_loss: 106.3580 - val_mae: 7.4185\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 8s 849ms/step - loss: 19.8993 - mae: 2.5758 - val_loss: 112.7092 - val_mae: 7.6460\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 20.0437 - mae: 2.6057 - val_loss: 117.7109 - val_mae: 7.9947\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 7s 737ms/step - loss: 19.2955 - mae: 2.5873 - val_loss: 106.8403 - val_mae: 7.4548\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 8s 755ms/step - loss: 18.3000 - mae: 2.4396 - val_loss: 104.1988 - val_mae: 7.3822\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 7s 740ms/step - loss: 18.6650 - mae: 2.4840 - val_loss: 112.2372 - val_mae: 7.7014\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 8s 783ms/step - loss: 17.9757 - mae: 2.4178 - val_loss: 107.8681 - val_mae: 7.5504\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 17.3953 - mae: 2.3557 - val_loss: 111.7195 - val_mae: 7.7005\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 8s 803ms/step - loss: 17.4344 - mae: 2.3747 - val_loss: 108.2892 - val_mae: 7.5305\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 18.3240 - mae: 2.4481 - val_loss: 106.1889 - val_mae: 7.3956\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 8s 828ms/step - loss: 19.0995 - mae: 2.5635 - val_loss: 111.5423 - val_mae: 7.5681\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 18.0668 - mae: 2.4400 - val_loss: 109.4062 - val_mae: 7.5891\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 8s 845ms/step - loss: 18.2191 - mae: 2.4363 - val_loss: 108.6467 - val_mae: 7.5742\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 7s 681ms/step - loss: 17.6049 - mae: 2.3715 - val_loss: 109.2244 - val_mae: 7.5641\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 8s 811ms/step - loss: 18.0017 - mae: 2.4097 - val_loss: 111.3432 - val_mae: 7.5974\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 7s 695ms/step - loss: 18.8216 - mae: 2.5221 - val_loss: 107.0989 - val_mae: 7.4423\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 8s 779ms/step - loss: 18.2601 - mae: 2.4692 - val_loss: 116.5045 - val_mae: 7.9111\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 7s 721ms/step - loss: 17.9339 - mae: 2.4162 - val_loss: 107.7274 - val_mae: 7.5023\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 7s 727ms/step - loss: 17.4519 - mae: 2.3625 - val_loss: 109.9122 - val_mae: 7.5621\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 8s 793ms/step - loss: 17.7876 - mae: 2.4194 - val_loss: 110.2672 - val_mae: 7.5456\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 8s 787ms/step - loss: 18.0122 - mae: 2.4544 - val_loss: 110.0184 - val_mae: 7.5862\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 8s 814ms/step - loss: 16.8844 - mae: 2.3104 - val_loss: 111.0427 - val_mae: 7.5613\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 7s 663ms/step - loss: 17.9126 - mae: 2.4315 - val_loss: 114.4797 - val_mae: 7.7703\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 8s 819ms/step - loss: 17.8245 - mae: 2.4326 - val_loss: 106.0376 - val_mae: 7.4627\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 18s 2s/step - loss: 18.2111 - mae: 2.4508 - val_loss: 111.8164 - val_mae: 7.6302\n",
      "Epoch 379/1000\n",
      " 5/10 [==============>...............] - ETA: 11s - loss: 16.1427 - mae: 2.3123"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "with open(os.path.join(RESULTS_DIR_ABS_PATH, 'output.txt'), 'w') as f:\n",
    "    X, y = load_data()\n",
    "    X_train, y_train, X_val, y_val = split_data(hps, X, y)\n",
    "\n",
    "    model = generate_model(hps)\n",
    "    tf.keras.utils.plot_model(model, os.path.join(RESULTS_DIR_ABS_PATH, 'model.png'), show_shapes=True)\n",
    "    model.summary()\n",
    "\n",
    "    #if (len(sys.argv) > 1):\n",
    "        #model.load_weights(sys.argv[1])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=hps.epochs,\n",
    "        batch_size=hps.batch_size,\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    model.save_weights(os.path.join(RESULTS_DIR_ABS_PATH, 'weights.h5'))\n",
    "\n",
    "    train_predictions = model.predict(X_train)\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    draw_results(y_train, train_predictions, 'train')\n",
    "    draw_results(y_val, val_predictions, 'validation')\n",
    "    draw_history(history)\n",
    "\n",
    "    f.write('loss: {}\\nmae: {}\\nval loss: {}\\nval mae: {}\\n'.format(\n",
    "        history.history['loss'][-1],\n",
    "        history.history['mae'][-1],\n",
    "        history.history['val_loss'][-1],\n",
    "        history.history['val_mae'][-1]\n",
    "    ))\n",
    "    f.write('val rho (min): {}\\nval rho (avg): {}\\nval rho (max): {}'.format(\n",
    "        np.corrcoef(y_val[:, 0], val_predictions[:, 0])[0, 1],\n",
    "        np.corrcoef(y_val[:, 1], val_predictions[:, 1])[0, 1],\n",
    "        np.corrcoef(y_val[:, 2], val_predictions[:, 2])[0, 1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f80552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
